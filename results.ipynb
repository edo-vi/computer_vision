{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this file I print the results as in the exprimental section. Because sometimes it dies due to memory, I saved the results in three pickles filed that you can load by setting the next parameter to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_saved_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 300 epoch finetuned yolo\n",
    "path_to_finetuned_checkpoint = \"/home/edoardo/aiproject/runs/detect/300/weights/best.pt\"\n",
    "model_tuned = YOLO(path_to_finetuned_checkpoint)\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save inference data (divided by noise type, due to kernel memory issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n",
      "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/home/edoardo/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 5.49MB/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife/valid/labels.cache... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.942       0.91      0.953      0.827\n",
      "               buffalo         62         89      0.951      0.899      0.948      0.824\n",
      "              elephant         53         91      0.909      0.876      0.931      0.802\n",
      "                 rhino         55         85      0.965      0.963      0.975      0.873\n",
      "                 zebra         59        114      0.945      0.903      0.959      0.808\n",
      "Speed: 0.5ms preprocess, 2.8ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val64\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if not use_saved_results:\n",
    "    results_clean = {}\n",
    "    # Clean dataset\n",
    "    inference_clean = model_tuned.val(data=\"wildlife.yaml\")\n",
    "    info = {\n",
    "        \"precision\": inference_clean.box.p,\n",
    "        \"recall\": inference_clean.box.r,\n",
    "        \"mAP\": inference_clean.box.all_ap,\n",
    "        \"confusion_matrix\": inference_clean.confusion_matrix,\n",
    "    }\n",
    "\n",
    "    results_clean[\"clean\"] = info.copy()\n",
    "    with open(\"results_detection_clean_yolo.pckl\", \"wb\") as file:\n",
    "        pickle.dump(results_clean, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n",
      "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife/valid/labels.cache... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/15 [00:00<?, ?it/s]/home/edoardo/anaconda3/envs/aiproject/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.942       0.91      0.953      0.827\n",
      "               buffalo         62         89      0.951      0.899      0.948      0.824\n",
      "              elephant         53         91      0.909      0.876      0.931      0.802\n",
      "                 rhino         55         85      0.965      0.963      0.975      0.873\n",
      "                 zebra         59        114      0.945      0.903      0.959      0.808\n",
      "Speed: 0.5ms preprocess, 2.8ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val50\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_gaussian_0.1_v0/valid/labels.cache... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.911      0.746      0.842      0.676\n",
      "               buffalo         62         89      0.949      0.742      0.876      0.735\n",
      "              elephant         53         91      0.818      0.741      0.775       0.62\n",
      "                 rhino         55         85      0.891      0.882      0.931       0.77\n",
      "                 zebra         59        114      0.986       0.62      0.785      0.581\n",
      "Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val51\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_gaussian_0.1_v1/valid/labels.cache... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379        0.9       0.75      0.835      0.672\n",
      "               buffalo         62         89      0.867      0.854      0.893      0.752\n",
      "              elephant         53         91      0.874      0.637      0.752      0.601\n",
      "                 rhino         55         85      0.903      0.918      0.939      0.781\n",
      "                 zebra         59        114      0.958      0.593      0.756      0.554\n",
      "Speed: 0.5ms preprocess, 1.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val52\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_gaussian_0.2_v0/valid/labels.cache... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379       0.87      0.693      0.786      0.606\n",
      "               buffalo         62         89      0.937      0.673      0.798      0.667\n",
      "              elephant         53         91        0.8      0.648       0.71      0.545\n",
      "                 rhino         55         85      0.783      0.847      0.868      0.664\n",
      "                 zebra         59        114      0.958      0.604      0.768      0.548\n",
      "Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val53\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_gaussian_0.2_v1/valid/labels.cache... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 12.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.804      0.617      0.705      0.513\n",
      "               buffalo         62         89      0.775      0.695       0.77      0.601\n",
      "              elephant         53         91      0.763      0.532      0.642      0.484\n",
      "                 rhino         55         85      0.784      0.853       0.86      0.638\n",
      "                 zebra         59        114      0.894      0.386      0.548      0.329\n",
      "Speed: 0.6ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val54\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if not use_saved_results:\n",
    "    results_gaussian = {}\n",
    "\n",
    "    # Noisy dataset\n",
    "    noises = {\"gaussian\": [0.1, 0.2], \"bernoulli\": [0.1, 0.3]}\n",
    "    for noise_type in [\"gaussian\"]:\n",
    "        results_gaussian[noise_type] = dict()\n",
    "        for noise in noises[noise_type]:\n",
    "            results_gaussian[noise_type][noise] = dict()\n",
    "            for model in [\"v0\", \"v1\"]:\n",
    "                inference_data = model_tuned.val(\n",
    "                    data=f\"wildlife_{noise_type}_{noise}_{model}.yaml\"\n",
    "                )\n",
    "                # Info to save\n",
    "                info = {\n",
    "                    \"precision\": inference_data.box.p,\n",
    "                    \"recall\": inference_data.box.r,\n",
    "                    \"mAP\": inference_data.box.all_ap,\n",
    "                    \"confusion_matrix\": inference_data.confusion_matrix,\n",
    "                }\n",
    "                results_gaussian[noise_type][noise][model] = info.copy()\n",
    "\n",
    "    with open(\"results_detection_gaussian_yolo.pckl\", \"wb\") as file:\n",
    "        pickle.dump(results_gaussian, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n",
      "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v0/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 1680.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v0/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   7%|â–‹         | 1/15 [00:00<00:01,  8.43it/s]/home/edoardo/anaconda3/envs/aiproject/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.923      0.779      0.875      0.732\n",
      "               buffalo         62         89      0.826      0.876      0.907      0.756\n",
      "              elephant         53         91      0.951      0.648      0.815      0.674\n",
      "                 rhino         55         85      0.962      0.882      0.949      0.822\n",
      "                 zebra         59        114      0.953      0.711      0.828      0.676\n",
      "Speed: 0.5ms preprocess, 2.8ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val58\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v1/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 1962.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v1/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.932      0.801      0.893      0.743\n",
      "               buffalo         62         89      0.867      0.854      0.938       0.77\n",
      "              elephant         53         91      0.931      0.741      0.849      0.697\n",
      "                 rhino         55         85      0.962      0.897      0.954      0.827\n",
      "                 zebra         59        114      0.968      0.711       0.83       0.68\n",
      "Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val59\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v2/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 2144.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v2/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.866      0.595      0.725      0.541\n",
      "               buffalo         62         89      0.835      0.738      0.784      0.638\n",
      "              elephant         53         91       0.82      0.449      0.665      0.491\n",
      "                 rhino         55         85      0.867        0.8      0.846      0.644\n",
      "                 zebra         59        114      0.943      0.395      0.604      0.391\n",
      "Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val60\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.3_v0/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 1826.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.3_v0/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.916      0.749      0.845      0.689\n",
      "               buffalo         62         89      0.752      0.843      0.847      0.702\n",
      "              elephant         53         91      0.993      0.571      0.793      0.626\n",
      "                 rhino         55         85      0.956      0.906      0.944      0.804\n",
      "                 zebra         59        114      0.961      0.675      0.797      0.624\n",
      "Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val61\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.3_v1/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 1764.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.3_v1/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.808      0.664       0.76      0.587\n",
      "               buffalo         62         89      0.676      0.787       0.81      0.659\n",
      "              elephant         53         91      0.804      0.495      0.671      0.502\n",
      "                 rhino         55         85       0.86      0.867      0.893      0.703\n",
      "                 zebra         59        114       0.89      0.509      0.665      0.482\n",
      "Speed: 0.6ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val62\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.3_v2/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 1898.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.3_v2/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.727      0.516      0.615      0.443\n",
      "               buffalo         62         89      0.518      0.685      0.656      0.507\n",
      "              elephant         53         91      0.741      0.363       0.53      0.372\n",
      "                 rhino         55         85      0.729      0.647       0.74      0.551\n",
      "                 zebra         59        114       0.92      0.368      0.534      0.343\n",
      "Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val63\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if not use_saved_results:\n",
    "    results_bernoulli = {}\n",
    "    # Noisy dataset\n",
    "    noises = {\"gaussian\": [0.1, 0.2], \"bernoulli\": [0.1, 0.3]}\n",
    "    for noise_type in [\"bernoulli\"]:\n",
    "        results_bernoulli[noise_type] = dict()\n",
    "        for noise in noises[noise_type]:\n",
    "            results_bernoulli[noise_type][noise] = dict()\n",
    "            for model in [\"v0\", \"v1\", \"v2\"]:\n",
    "                inference_data = model_tuned.val(\n",
    "                    data=f\"wildlife_{noise_type}_{noise}_{model}.yaml\"\n",
    "                )\n",
    "                # Info to save\n",
    "                info = {\n",
    "                    \"precision\": inference_data.box.p,\n",
    "                    \"recall\": inference_data.box.r,\n",
    "                    \"mAP\": inference_data.box.all_ap,\n",
    "                    \"confusion_matrix\": inference_data.confusion_matrix,\n",
    "                }\n",
    "                results_bernoulli[noise_type][noise][model] = info.copy()\n",
    "\n",
    "    with open(\"results_detection_bernoulli_yolo.pckl\", \"wb\") as file:\n",
    "        pickle.dump(results_bernoulli, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load clean, Gaussian and Bernoulli results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results_detection_clean_yolo.pckl\", \"rb\") as file:\n",
    "    results_clean = pickle.load(file)\n",
    "with open(\"results_detection_gaussian_yolo.pckl\", \"rb\") as file:\n",
    "    results_gaussian = pickle.load(file)\n",
    "with open(\"results_detection_bernoulli_yolo.pckl\", \"rb\") as file:\n",
    "    results_bernoulli = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.942 0.91  0.827]\n",
      " [0.951 0.899 0.824]\n",
      " [0.909 0.876 0.802]\n",
      " [0.965 0.963 0.873]\n",
      " [0.945 0.903 0.808]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "names = [\"Buffalo\", \"Elephant\", \"Rhino\", \"Zebra\"]\n",
    "indexes = range(4)\n",
    "# Clean dataset\n",
    "\n",
    "\n",
    "# Simple utility just to print the matrixes. These functions are a bit complex and not really interesting\n",
    "# They are just used to help me printing the latex tables\n",
    "def get_res_matrix(result, noise_type, noises, model_kinds):\n",
    "    matrixes = []\n",
    "    for noise in noises:\n",
    "        # V0\n",
    "        matrix_kind = []\n",
    "        for kind in model_kinds:\n",
    "            res = result[noise_type][noise][kind]\n",
    "            matr = np.zeros(\n",
    "                (len(indexes) + 1, 3 * 1)\n",
    "            )  # matrix that we update with the values to print\n",
    "            matr[:, 0] = [\n",
    "                res[\"precision\"].mean(),\n",
    "                *res[\"precision\"],\n",
    "            ]\n",
    "            matr[:, 1] = [\n",
    "                res[\"recall\"].mean(),\n",
    "                *res[\"recall\"],\n",
    "            ]\n",
    "            # mAP50-95\n",
    "            mAP50 = np.array([res[\"mAP\"][j].mean() for j in indexes])\n",
    "            matr[:, 2] = [\n",
    "                mAP50.mean(),\n",
    "                *mAP50,\n",
    "            ]\n",
    "            matrix_kind.append(matr)\n",
    "\n",
    "        matrixes.append(np.hstack(matrix_kind))\n",
    "    return np.vstack(matrixes)\n",
    "\n",
    "\n",
    "# Baseline: the cleaned dataset\n",
    "\n",
    "matr_cleaned = np.zeros((len(indexes) + 1, 3 * 1))\n",
    "\n",
    "matr_cleaned[:, 0] = [\n",
    "    results_clean[\"clean\"][\"precision\"].mean(),\n",
    "    *results_clean[\"clean\"][\"precision\"],\n",
    "]\n",
    "matr_cleaned[:, 1] = [\n",
    "    results_clean[\"clean\"][\"recall\"].mean(),\n",
    "    *results_clean[\"clean\"][\"recall\"],\n",
    "]\n",
    "# mAP50-95\n",
    "mAP50_c = np.array([results_clean[\"clean\"][\"mAP\"][j].mean() for j in indexes])\n",
    "matr_cleaned[:, 2] = [mAP50_c.mean(), *mAP50_c]\n",
    "print(matr_cleaned)\n",
    "\n",
    "# The Gaussian result matrix\n",
    "\n",
    "res_matrix_gaussian = get_res_matrix(\n",
    "    results_gaussian, \"gaussian\", [0.1, 0.2], [\"v0\", \"v1\"]\n",
    ")\n",
    "\n",
    "# The Bernoulli result matrix\n",
    "res_matrix_bernoulli = get_res_matrix(\n",
    "    results_bernoulli, \"bernoulli\", [0.1, 0.3], [\"v2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facility for printing the latex table of the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All & 255 && 0.942& 0.91& 0.827\\\\ \n",
      "Buffalo & 89 && 0.951& 0.899& 0.824\\\\ \n",
      "Elephant & 91 && 0.909& 0.876& 0.802\\\\ \n",
      "Rhino & 85 && 0.965& 0.963& 0.873\\\\ \n",
      "Zebra & 114 &&0.945& 0.903& 0.808\\\\ \n",
      "\n",
      "All & 255 && 0.911& 0.746& 0.676& 0.9& 0.75& 0.672\\\\ \n",
      "Buffalo & 89 && 0.949& 0.742& 0.735& 0.867& 0.854& 0.752\\\\ \n",
      "Elephant & 91 && 0.818& 0.741& 0.62& 0.874& 0.637& 0.601\\\\ \n",
      "Rhino & 85 && 0.891& 0.882& 0.77& 0.903& 0.918& 0.781\\\\ \n",
      "Zebra & 114 &&0.986& 0.62& 0.581& 0.958& 0.593& 0.554\\\\ \n",
      "All & 255 && 0.87& 0.693& 0.606& 0.804& 0.617& 0.513\\\\ \n",
      "Buffalo & 89 && 0.937& 0.673& 0.667& 0.775& 0.695& 0.601\\\\ \n",
      "Elephant & 91 && 0.8& 0.648& 0.545& 0.763& 0.532& 0.484\\\\ \n",
      "Rhino & 85 && 0.783& 0.847& 0.664& 0.784& 0.853& 0.638\\\\ \n",
      "Zebra & 114 &&0.958& 0.604& 0.548& 0.894& 0.386& 0.329\\\\ \n",
      "\n",
      "All & 255 && 0.866& 0.595& 0.541\\\\ \n",
      "Buffalo & 89 && 0.835& 0.738& 0.638\\\\ \n",
      "Elephant & 91 && 0.82& 0.449& 0.491\\\\ \n",
      "Rhino & 85 && 0.867& 0.8& 0.644\\\\ \n",
      "Zebra & 114 &&0.943& 0.395& 0.391\\\\ \n",
      "All & 255 && 0.727& 0.516& 0.443\\\\ \n",
      "Buffalo & 89 && 0.518& 0.685& 0.507\\\\ \n",
      "Elephant & 91 && 0.741& 0.363& 0.372\\\\ \n",
      "Rhino & 85 && 0.729& 0.647& 0.551\\\\ \n",
      "Zebra & 114 &&0.92& 0.368& 0.343\\\\ \n"
     ]
    }
   ],
   "source": [
    "# Latex table formatting\n",
    "def latex_table_formatting(res_matrix):\n",
    "    rows = [\n",
    "        \"All & 255 && \",\n",
    "        \"Buffalo & 89 && \",\n",
    "        \"Elephant & 91 && \",\n",
    "        \"Rhino & 85 && \",\n",
    "        \"Zebra & 114 &&\",\n",
    "    ]\n",
    "    if len(res_matrix) > 5:\n",
    "        rows += [\n",
    "            \"All & 255 && \",\n",
    "            \"Buffalo & 89 && \",\n",
    "            \"Elephant & 91 && \",\n",
    "            \"Rhino & 85 && \",\n",
    "            \"Zebra & 114 &&\",\n",
    "        ]\n",
    "    for i in range(len(rows)):\n",
    "        print(\n",
    "            rows[i] + \"& \".join([str(round(r, 3)) for r in res_matrix[i]]),\n",
    "            end=\"\\\\\\\\ \\n\",\n",
    "        )\n",
    "\n",
    "\n",
    "latex_table_formatting(matr_cleaned)\n",
    "print(\"\")\n",
    "latex_table_formatting(res_matrix_gaussian)\n",
    "print(\"\")\n",
    "latex_table_formatting(res_matrix_bernoulli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facility for printing the confusion matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffalo & 81 & 0 & 0 & 0 & 4\\\\\n",
      "Elephant & 3 & 82 & 1 & 1 & 8\\\\\n",
      "Rhino & 0 & 0 & 80 & 1 & 6\\\\\n",
      "Zebra & 0 & 0 & 1 & 104 & 14\\\\\n",
      "Backgr. & 5 & 9 & 3 & 8 & 0\\\\\n",
      "Gaussian\n",
      "\n",
      "0.1 | v0\n",
      "Buffalo & 68 & 0 & 0 & 0 & 3\\\\\n",
      "Elephant & 6 & 69 & 1 & 6 & 6\\\\\n",
      "Rhino & 0 & 1 & 77 & 2 & 5\\\\\n",
      "Zebra & 0 & 0 & 0 & 71 & 4\\\\\n",
      "Backgr. & 15 & 21 & 7 & 35 & 0\\\\\n",
      "\n",
      "0.1 | v1\n",
      "Buffalo & 76 & 1 & 2 & 1 & 5\\\\\n",
      "Elephant & 2 & 56 & 1 & 4 & 1\\\\\n",
      "Rhino & 0 & 4 & 76 & 2 & 2\\\\\n",
      "Zebra & 0 & 0 & 0 & 66 & 1\\\\\n",
      "Backgr. & 11 & 30 & 6 & 41 & 0\\\\\n",
      "\n",
      "0.2 | v0\n",
      "Buffalo & 58 & 0 & 1 & 0 & 3\\\\\n",
      "Elephant & 6 & 57 & 1 & 3 & 3\\\\\n",
      "Rhino & 2 & 2 & 69 & 4 & 6\\\\\n",
      "Zebra & 0 & 0 & 0 & 68 & 1\\\\\n",
      "Backgr. & 23 & 32 & 14 & 39 & 0\\\\\n",
      "\n",
      "0.2 | v1\n",
      "Buffalo & 60 & 3 & 1 & 1 & 8\\\\\n",
      "Elephant & 3 & 42 & 1 & 3 & 3\\\\\n",
      "Rhino & 0 & 5 & 71 & 2 & 8\\\\\n",
      "Zebra & 0 & 0 & 0 & 39 & 1\\\\\n",
      "Backgr. & 26 & 41 & 12 & 69 & 0\\\\\n",
      "\n",
      "Bernoulli\n",
      "\n",
      "0.1 | v0\n",
      "Buffalo & 80 & 8 & 1 & 2 & 9\\\\\n",
      "Elephant & 0 & 59 & 1 & 2 & 5\\\\\n",
      "Rhino & 0 & 2 & 77 & 2 & 3\\\\\n",
      "Zebra & 0 & 0 & 1 & 83 & 5\\\\\n",
      "Backgr. & 9 & 22 & 5 & 25 & 0\\\\\n",
      "\n",
      "0.1 | v1\n",
      "Buffalo & 78 & 3 & 2 & 2 & 9\\\\\n",
      "Elephant & 0 & 66 & 1 & 4 & 2\\\\\n",
      "Rhino & 1 & 2 & 77 & 1 & 0\\\\\n",
      "Zebra & 0 & 0 & 1 & 81 & 4\\\\\n",
      "Backgr. & 10 & 20 & 4 & 26 & 0\\\\\n",
      "\n",
      "0.3 | v0\n",
      "Buffalo & 78 & 12 & 1 & 5 & 4\\\\\n",
      "Elephant & 0 & 52 & 0 & 0 & 0\\\\\n",
      "Rhino & 0 & 2 & 77 & 1 & 0\\\\\n",
      "Zebra & 0 & 0 & 0 & 77 & 3\\\\\n",
      "Backgr. & 11 & 25 & 7 & 31 & 0\\\\\n",
      "\n",
      "0.3 | v1\n",
      "Buffalo & 66 & 14 & 4 & 1 & 9\\\\\n",
      "Elephant & 6 & 36 & 0 & 0 & 7\\\\\n",
      "Rhino & 0 & 6 & 70 & 1 & 3\\\\\n",
      "Zebra & 0 & 0 & 0 & 60 & 1\\\\\n",
      "Backgr. & 17 & 35 & 11 & 52 & 0\\\\\n"
     ]
    }
   ],
   "source": [
    "# Columns are the ground truth (in order: buffalo, elephant, rhino, zebra, background), the rows the prediction\n",
    "def print_cf_matrix(res, names=names):\n",
    "    for i, n in enumerate(names + [\"Backgr.\"]):\n",
    "        print(f\"{n} & {' & '.join(list(res[i].astype(int).astype(str)))}\\\\\\\\\")\n",
    "\n",
    "\n",
    "# Clean\n",
    "res = results_clean[\"clean\"][\"confusion_matrix\"].matrix\n",
    "print_cf_matrix(res)\n",
    "\n",
    "print(\"Gaussian\")\n",
    "# Gaussian\n",
    "noises = [0.1, 0.2]\n",
    "models = [\"v0\", \"v1\"]\n",
    "for n in noises:\n",
    "    for m in models:\n",
    "        print(f\"\\n{n} | {m}\")\n",
    "        res = results_gaussian[\"gaussian\"][n][m][\"confusion_matrix\"].matrix\n",
    "        print_cf_matrix(res)\n",
    "\n",
    "print(\"\\nBernoulli\")\n",
    "# Bernoulli\n",
    "noises = [0.1, 0.3]\n",
    "models = [\"v0\", \"v1\"]\n",
    "for n in noises:\n",
    "    for m in models:\n",
    "        print(f\"\\n{n} | {m}\")\n",
    "        res = results_bernoulli[\"bernoulli\"][n][m][\"confusion_matrix\"].matrix\n",
    "        print_cf_matrix(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
