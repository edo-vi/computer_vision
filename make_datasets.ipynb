{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedConfigFileIncludesAndImports(filename='config.cfg', imports=[], includes=[])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "from DataLoader import (\n",
    "    AfricanWildlifeDataset,\n",
    "    bernoulli_noise_transform,\n",
    "    gaussian_noise_transform,\n",
    ")\n",
    "from DenoisingAE import DenoisingAE, DenoisingAEV1, DenoisingAEV2\n",
    "from DenoisingResnet import DenoisingResnet\n",
    "import torch\n",
    "import gc\n",
    "import torchvision\n",
    "import yaml\n",
    "import gin\n",
    "import os\n",
    "from itertools import product\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.image\n",
    "import cv2\n",
    "\n",
    "checkpoints = {\n",
    "    \"gaussian\": {\n",
    "        0.1: {\n",
    "            \"v0\": \"denoising_checkpoints/gaussian/0.1/v0/best.ckpt\",\n",
    "            \"v1\": \"denoising_checkpoints/gaussian/0.1/v1/best.ckpt\",\n",
    "            \"v2\": \"denoising_checkpoints/gaussian/0.1/v2/best.ckpt\",\n",
    "        },\n",
    "        0.2: {\n",
    "            \"v0\": \"denoising_checkpoints/gaussian/0.2/v0/best.ckpt\",\n",
    "            \"v1\": \"denoising_checkpoints/gaussian/0.2/v1/best.ckpt\",\n",
    "            \"v2\": \"denoising_checkpoints/gaussian/0.2/v2/best.ckpt\",\n",
    "        },\n",
    "    },\n",
    "    \"bernoulli\": {\n",
    "        0.1: {\n",
    "            \"v0\": \"denoising_checkpoints/bernoulli/0.1/v0/best.ckpt\",\n",
    "            \"v1\": \"denoising_checkpoints/bernoulli/0.1/v1/best.ckpt\",\n",
    "            \"v2\": \"denoising_checkpoints/bernoulli/0.1/v2/best.ckpt\",\n",
    "        },\n",
    "        0.3: {\n",
    "            \"v0\": \"denoising_checkpoints/bernoulli/0.3/v0/best.ckpt\",\n",
    "            \"v1\": \"denoising_checkpoints/bernoulli/0.3/v1/best.ckpt\",\n",
    "            \"v2\": \"denoising_checkpoints/bernoulli/0.3/v2/best.ckpt\",\n",
    "        },\n",
    "    },\n",
    "}\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "gin.parse_config_file(\"config.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': '../datasets/wildlife', 'train': 'train/images', 'val': 'valid/images', 'test': 'test/images', 'names': {0: 'buffalo', 1: 'elephant', 2: 'rhino', 3: 'zebra'}}\n",
      "{'path': '../datasets/wildlife', 'train': 'train/images', 'val': 'valid/images', 'test': 'test/images', 'names': {0: 'buffalo', 1: 'elephant', 2: 'rhino', 3: 'zebra'}, 'datasets_dir': '/home/edoardo/aiproject/aaa'}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "y = None\n",
    "with open(f\"./wildlife.yaml\") as stream:\n",
    "    this_path = os.path.join(os.getcwd(), \"aaa\")\n",
    "    try:\n",
    "        y = yaml.safe_load(stream)\n",
    "        print(y)\n",
    "        y[\"datasets_dir\"] = this_path\n",
    "        print(y)\n",
    "        # yaml.safe_dump(y, stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "# with open(f\"{Path.home()}/.config/Ultralytics/settings.yaml\", \"w\") as f:\n",
    "#     yaml.dump(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edoardo/anaconda3/envs/aiproject/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "def copy_images(dataset, model, noise_type, noise):\n",
    "    for index in range(len(dataset)):\n",
    "        img, orig = dataset[index]\n",
    "        shape = dataset.image_dimensions[index]\n",
    "        original_name = dataset.list_dir[index]\n",
    "\n",
    "        t = torchvision.transforms.Resize((shape[1], shape[2]))\n",
    "\n",
    "        # Clean and returning to the original size\n",
    "        cleanedv0 = t(model(img.to(\"cuda\")).detach().cpu())\n",
    "        # Transpose the axes to make it WHC and reconvert it to a [0,...,255] image\n",
    "        normalized = np.transpose((cleanedv0 * 255).numpy(), [1, 2, 0]).astype(\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "        matplotlib.image.imsave(\n",
    "            f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/{dataset.kind}/images/{original_name}\",\n",
    "            normalized,\n",
    "        )\n",
    "\n",
    "\n",
    "noises = {\"gaussian\": [0.1, 0.2], \"bernoulli\": [0.1, 0.3]}\n",
    "\n",
    "for noise_type in [\"gaussian\", \"bernoulli\"]:\n",
    "    for noise in noises[noise_type]:\n",
    "        if noise_type == \"gaussian\":\n",
    "            noise_transform = gaussian_noise_transform(0, noise, width=640)\n",
    "        else:\n",
    "            noise_transform = bernoulli_noise_transform(noise, width=640)\n",
    "        modelv2 = DenoisingAEV2.load_from_checkpoint(\n",
    "            checkpoints[noise_type][noise][\"v2\"]\n",
    "        )\n",
    "        modelv1 = DenoisingAEV1.load_from_checkpoint(\n",
    "            checkpoints[noise_type][noise][\"v1\"]\n",
    "        )\n",
    "        modelv0 = DenoisingAE.load_from_checkpoint(checkpoints[noise_type][noise][\"v0\"])\n",
    "        for model in [modelv0, modelv1, modelv2]:\n",
    "            train_dataset = AfricanWildlifeDataset(\n",
    "                kind=\"train\", transform=noise_transform\n",
    "            )\n",
    "            val_dataset = AfricanWildlifeDataset(\n",
    "                kind=\"valid\", transform=noise_transform\n",
    "            )\n",
    "            test_dataset = AfricanWildlifeDataset(\n",
    "                kind=\"test\", transform=noise_transform\n",
    "            )\n",
    "            dataset_yaml = dict(\n",
    "                {\n",
    "                    \"path\": f\"../datasets/wildlife_{noise_type}_{noise}_{model.kind}\",\n",
    "                    \"train\": \"train/images\",\n",
    "                    \"val\": \"valid/images\",\n",
    "                    \"test\": \"test/images\",\n",
    "                    \"names\": {0: \"buffalo\", 1: \"elephant\", 2: \"rhino\", 3: \"zebra\"},\n",
    "                }\n",
    "            )\n",
    "            with open(f\"./wildlife_{noise_type}_{noise}_{model.kind}.yaml\", \"w\") as f:\n",
    "                yaml.dump(dataset_yaml, f)\n",
    "            os.mkdir(f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}\")\n",
    "\n",
    "            os.mkdir(f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/train\")\n",
    "            os.mkdir(\n",
    "                f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/train/images\"\n",
    "            )\n",
    "            # we just copy the labels because we have kept the right image dimensions\n",
    "            shutil.copytree(\n",
    "                \"datasets/wildlife/train/labels\",\n",
    "                f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/train/labels\",\n",
    "            )\n",
    "            os.mkdir(f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/test\")\n",
    "            os.mkdir(f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/test/images\")\n",
    "            # we just copy the labels because we have kept the right image dimensions\n",
    "            shutil.copytree(\n",
    "                \"datasets/wildlife/test/labels\",\n",
    "                f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/test/labels\",\n",
    "            )\n",
    "            os.mkdir(f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/valid\")\n",
    "            os.mkdir(\n",
    "                f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/valid/images\"\n",
    "            )\n",
    "            # we just copy the labels because we have kept the right image dimensions\n",
    "            shutil.copytree(\n",
    "                \"datasets/wildlife/valid/labels\",\n",
    "                f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/valid/labels\",\n",
    "            )\n",
    "            copy_images(train_dataset, model, noise_type, noise)\n",
    "            copy_images(test_dataset, model, noise_type, noise)\n",
    "            copy_images(val_dataset, model, noise_type, noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
