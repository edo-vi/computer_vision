{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File used to create the datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, to use Ultralytics's YOLO we need to add the datasets (divided into train/test/valid, with each one having two folders: images and labels) inside the folder indicated in the file usually found in the path $HOME/.config/Ultralytics/settings.yaml\". Then, we also need a yaml defining the path of the dataset, the number of classes etc. in the root of this folder. \n",
    "\n",
    "The point of this notebook is to automate the process of: taking the dataset, adding it the wanted noise, using the wanted model to denoising, and the save this \"reconstructed dataset\" in this format (i.e. in the correct folder), and then create the correct yaml to describe it, so that we can use YOLO on this reconstructed folder.\n",
    "\n",
    "See for example \"african_wildlife.yaml\" or \"wildlife_bernoulli_0.1_v0.yaml\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedConfigFileIncludesAndImports(filename='config.cfg', imports=[], includes=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "from DataLoader import (\n",
    "    AfricanWildlifeDataset,\n",
    "    bernoulli_noise_transform,\n",
    "    gaussian_noise_transform,\n",
    ")\n",
    "from DenoisingAE import DenoisingAE, DenoisingAEV1, DenoisingAEV2\n",
    "from DenoisingResnet import DenoisingResnet\n",
    "import torch\n",
    "import gc\n",
    "import torchvision\n",
    "import yaml\n",
    "import gin\n",
    "import os\n",
    "from itertools import product\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.image\n",
    "import cv2\n",
    "\n",
    "checkpoints = {\n",
    "    \"gaussian\": {\n",
    "        0.1: {\n",
    "            \"v0\": \"denoising_checkpoints/gaussian/0.1/v0/best.ckpt\",\n",
    "            \"v1\": \"denoising_checkpoints/gaussian/0.1/v1/best.ckpt\",\n",
    "            \"v2\": \"denoising_checkpoints/gaussian/0.1/v2/best.ckpt\",\n",
    "        },\n",
    "        0.2: {\n",
    "            \"v0\": \"denoising_checkpoints/gaussian/0.2/v0/best.ckpt\",\n",
    "            \"v1\": \"denoising_checkpoints/gaussian/0.2/v1/best.ckpt\",\n",
    "            \"v2\": \"denoising_checkpoints/gaussian/0.2/v2/best.ckpt\",\n",
    "        },\n",
    "    },\n",
    "    \"bernoulli\": {\n",
    "        0.1: {\n",
    "            \"v0\": \"denoising_checkpoints/bernoulli/0.1/v0/best.ckpt\",\n",
    "            \"v1\": \"denoising_checkpoints/bernoulli/0.1/v1/best.ckpt\",\n",
    "            \"v2\": \"denoising_checkpoints/bernoulli/0.1/v2/best.ckpt\",\n",
    "        },\n",
    "        0.3: {\n",
    "            \"v0\": \"denoising_checkpoints/bernoulli/0.3/v0/best.ckpt\",\n",
    "            \"v1\": \"denoising_checkpoints/bernoulli/0.3/v1/best.ckpt\",\n",
    "            \"v2\": \"denoising_checkpoints/bernoulli/0.3/v2/best.ckpt\",\n",
    "        },\n",
    "    },\n",
    "}\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "gin.parse_config_file(\"config.cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: if you have already yolo or you just download it, it won't find the datasets in this project unless you set the 'datasets_dir' param in $Home/.config/Ultralytics/settings.yaml correctly (to the datasets folder in this project). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can do the above process by setting the following variable to True.\n",
    "set_correct_dataset_folder = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "if set_correct_dataset_folder:\n",
    "    y = None\n",
    "    with open(f\"{Path.home()}/.config/Ultralytics/settings.yaml\", \"r\") as stream:\n",
    "        this_dataset_folder = os.path.join(os.getcwd(), \"datasets\")\n",
    "        try:\n",
    "            y = yaml.safe_load(stream)\n",
    "            print(\"Before: \", y)\n",
    "            y[\"datasets_dir\"] = this_dataset_folder\n",
    "            print(\"After: \", y)\n",
    "\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "\n",
    "    with open(f\"{Path.home()}/.config/Ultralytics/settings.yaml\", \"w\") as f:\n",
    "        yaml.dump(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'datasets/wildlife_gaussian_0.1_v0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./wildlife_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     58\u001b[0m     yaml\u001b[38;5;241m.\u001b[39mdump(dataset_yaml, f)\n\u001b[0;32m---> 59\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets/wildlife_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnoise_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnoise\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/wildlife_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/train\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/wildlife_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/train/images\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m )\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'datasets/wildlife_gaussian_0.1_v0'"
     ]
    }
   ],
   "source": [
    "# Helper to copy the images in the correct folder\n",
    "def copy_images(dataset, model, noise_type, noise):\n",
    "    for index in range(len(dataset)):\n",
    "        img, _ = dataset[index]\n",
    "        shape = dataset.image_dimensions[index]\n",
    "        original_name = dataset.list_dir[index]\n",
    "\n",
    "        t = torchvision.transforms.Resize((shape[1], shape[2]))\n",
    "\n",
    "        # Clean and returning to the original size\n",
    "        cleanedv0 = t(model(img.to(\"cuda\")).detach().cpu())\n",
    "        # Transpose the axes to make it WHC and reconvert it to a [0,...,255] image\n",
    "        normalized = np.transpose((cleanedv0 * 255).numpy(), [1, 2, 0]).astype(\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "        matplotlib.image.imsave(\n",
    "            f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/{dataset.kind}/images/{original_name}\",\n",
    "            normalized,\n",
    "        )\n",
    "\n",
    "\n",
    "noises = {\"gaussian\": [0.1, 0.2], \"bernoulli\": [0.1, 0.3]}\n",
    "\n",
    "# Create the datasets, for all noises and denoising models.\n",
    "# NOTE: it won't work if the datasets are already present\n",
    "for noise_type in [\"gaussian\", \"bernoulli\"]:\n",
    "    for noise in noises[noise_type]:\n",
    "        if noise_type == \"gaussian\":\n",
    "            noise_transform = gaussian_noise_transform(0, noise, width=640)\n",
    "        else:\n",
    "            noise_transform = bernoulli_noise_transform(noise, width=640)\n",
    "        modelv2 = DenoisingAEV2.load_from_checkpoint(\n",
    "            checkpoints[noise_type][noise][\"v2\"]\n",
    "        )\n",
    "        modelv1 = DenoisingAEV1.load_from_checkpoint(\n",
    "            checkpoints[noise_type][noise][\"v1\"]\n",
    "        )\n",
    "        modelv0 = DenoisingAE.load_from_checkpoint(checkpoints[noise_type][noise][\"v0\"])\n",
    "        for model in [modelv0, modelv1, modelv2]:\n",
    "            train_dataset = AfricanWildlifeDataset(\n",
    "                kind=\"train\", transform=noise_transform\n",
    "            )\n",
    "            val_dataset = AfricanWildlifeDataset(\n",
    "                kind=\"valid\", transform=noise_transform\n",
    "            )\n",
    "            test_dataset = AfricanWildlifeDataset(\n",
    "                kind=\"test\", transform=noise_transform\n",
    "            )\n",
    "            dataset_yaml = dict(\n",
    "                {\n",
    "                    \"path\": f\"../datasets/wildlife_{noise_type}_{noise}_{model.kind}\",\n",
    "                    \"train\": \"train/images\",\n",
    "                    \"val\": \"valid/images\",\n",
    "                    \"test\": \"test/images\",\n",
    "                    \"names\": {0: \"buffalo\", 1: \"elephant\", 2: \"rhino\", 3: \"zebra\"},\n",
    "                }\n",
    "            )\n",
    "            with open(f\"./wildlife_{noise_type}_{noise}_{model.kind}.yaml\", \"w\") as f:\n",
    "                yaml.dump(dataset_yaml, f)\n",
    "            os.mkdir(f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}\")\n",
    "\n",
    "            os.mkdir(f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/train\")\n",
    "            os.mkdir(\n",
    "                f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/train/images\"\n",
    "            )\n",
    "            # we just copy the labels because we have kept the right image dimensions\n",
    "            shutil.copytree(\n",
    "                \"datasets/wildlife/train/labels\",\n",
    "                f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/train/labels\",\n",
    "            )\n",
    "            os.mkdir(f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/test\")\n",
    "            os.mkdir(f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/test/images\")\n",
    "            # we just copy the labels because we have kept the right image dimensions\n",
    "            shutil.copytree(\n",
    "                \"datasets/wildlife/test/labels\",\n",
    "                f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/test/labels\",\n",
    "            )\n",
    "            os.mkdir(f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/valid\")\n",
    "            os.mkdir(\n",
    "                f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/valid/images\"\n",
    "            )\n",
    "            # we just copy the labels because we have kept the right image dimensions\n",
    "            shutil.copytree(\n",
    "                \"datasets/wildlife/valid/labels\",\n",
    "                f\"datasets/wildlife_{noise_type}_{noise}_{model.kind}/valid/labels\",\n",
    "            )\n",
    "            copy_images(train_dataset, model, noise_type, noise)\n",
    "            copy_images(test_dataset, model, noise_type, noise)\n",
    "            copy_images(val_dataset, model, noise_type, noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
