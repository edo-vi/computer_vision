{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_pretrained_checkpoint = (\n",
    "    \"/home/edoardo/aiproject/runs/detect/300/weights/best.pt\"\n",
    ")\n",
    "model_tuned = YOLO(path_to_pretrained_checkpoint)\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save inference data (divided by noise type, due to kernel memory issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n",
      "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife/valid/labels.cache... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/15 [00:00<?, ?it/s]/home/edoardo/anaconda3/envs/aiproject/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.942       0.91      0.953      0.827\n",
      "               buffalo         62         89      0.951      0.899      0.948      0.824\n",
      "              elephant         53         91      0.909      0.876      0.931      0.802\n",
      "                 rhino         55         85      0.965      0.963      0.975      0.873\n",
      "                 zebra         59        114      0.945      0.903      0.959      0.808\n",
      "Speed: 0.5ms preprocess, 2.8ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val50\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_gaussian_0.1_v0/valid/labels.cache... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.911      0.746      0.842      0.676\n",
      "               buffalo         62         89      0.949      0.742      0.876      0.735\n",
      "              elephant         53         91      0.818      0.741      0.775       0.62\n",
      "                 rhino         55         85      0.891      0.882      0.931       0.77\n",
      "                 zebra         59        114      0.986       0.62      0.785      0.581\n",
      "Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val51\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_gaussian_0.1_v1/valid/labels.cache... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379        0.9       0.75      0.835      0.672\n",
      "               buffalo         62         89      0.867      0.854      0.893      0.752\n",
      "              elephant         53         91      0.874      0.637      0.752      0.601\n",
      "                 rhino         55         85      0.903      0.918      0.939      0.781\n",
      "                 zebra         59        114      0.958      0.593      0.756      0.554\n",
      "Speed: 0.5ms preprocess, 1.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val52\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_gaussian_0.2_v0/valid/labels.cache... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379       0.87      0.693      0.786      0.606\n",
      "               buffalo         62         89      0.937      0.673      0.798      0.667\n",
      "              elephant         53         91        0.8      0.648       0.71      0.545\n",
      "                 rhino         55         85      0.783      0.847      0.868      0.664\n",
      "                 zebra         59        114      0.958      0.604      0.768      0.548\n",
      "Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val53\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_gaussian_0.2_v1/valid/labels.cache... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 12.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.804      0.617      0.705      0.513\n",
      "               buffalo         62         89      0.775      0.695       0.77      0.601\n",
      "              elephant         53         91      0.763      0.532      0.642      0.484\n",
      "                 rhino         55         85      0.784      0.853       0.86      0.638\n",
      "                 zebra         59        114      0.894      0.386      0.548      0.329\n",
      "Speed: 0.6ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val54\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results_clean = {}\n",
    "results_gaussian = {}\n",
    "\n",
    "# Clean dataset\n",
    "inference_clean = model_tuned.val(data=\"wildlife.yaml\")\n",
    "info = {\n",
    "    \"precision\": inference_clean.box.p,\n",
    "    \"recall\": inference_clean.box.r,\n",
    "    \"mAP\": inference_clean.box.all_ap,\n",
    "    \"confusion_matrix\": inference_clean.confusion_matrix,\n",
    "}\n",
    "\n",
    "results_clean[\"clean\"] = info.copy()\n",
    "with open(\"results_detection_clean_yolo.pckl\", \"wb\") as file:\n",
    "    pickle.dump(results_clean, file)\n",
    "\n",
    "# Noisy dataset\n",
    "noises = {\"gaussian\": [0.1, 0.2], \"bernoulli\": [0.1, 0.3]}\n",
    "for noise_type in [\"gaussian\"]:\n",
    "    results_gaussian[noise_type] = dict()\n",
    "    for noise in noises[noise_type]:\n",
    "        results_gaussian[noise_type][noise] = dict()\n",
    "        for model in [\"v0\", \"v1\"]:\n",
    "            inference_data = model_tuned.val(\n",
    "                data=f\"wildlife_{noise_type}_{noise}_{model}.yaml\"\n",
    "            )\n",
    "            # Info to save\n",
    "            info = {\n",
    "                \"precision\": inference_data.box.p,\n",
    "                \"recall\": inference_data.box.r,\n",
    "                \"mAP\": inference_data.box.all_ap,\n",
    "                \"confusion_matrix\": inference_data.confusion_matrix,\n",
    "            }\n",
    "            results_gaussian[noise_type][noise][model] = info.copy()\n",
    "\n",
    "with open(\"results_detection_gaussian_yolo.pckl\", \"wb\") as file:\n",
    "    pickle.dump(results_gaussian, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n",
      "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v0/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 1680.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v0/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   7%|â–‹         | 1/15 [00:00<00:01,  8.43it/s]/home/edoardo/anaconda3/envs/aiproject/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.923      0.779      0.875      0.732\n",
      "               buffalo         62         89      0.826      0.876      0.907      0.756\n",
      "              elephant         53         91      0.951      0.648      0.815      0.674\n",
      "                 rhino         55         85      0.962      0.882      0.949      0.822\n",
      "                 zebra         59        114      0.953      0.711      0.828      0.676\n",
      "Speed: 0.5ms preprocess, 2.8ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val58\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v1/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 1962.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v1/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.932      0.801      0.893      0.743\n",
      "               buffalo         62         89      0.867      0.854      0.938       0.77\n",
      "              elephant         53         91      0.931      0.741      0.849      0.697\n",
      "                 rhino         55         85      0.962      0.897      0.954      0.827\n",
      "                 zebra         59        114      0.968      0.711       0.83       0.68\n",
      "Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val59\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v2/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 2144.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v2/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.866      0.595      0.725      0.541\n",
      "               buffalo         62         89      0.835      0.738      0.784      0.638\n",
      "              elephant         53         91       0.82      0.449      0.665      0.491\n",
      "                 rhino         55         85      0.867        0.8      0.846      0.644\n",
      "                 zebra         59        114      0.943      0.395      0.604      0.391\n",
      "Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val60\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.3_v0/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 1826.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.3_v0/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.916      0.749      0.845      0.689\n",
      "               buffalo         62         89      0.752      0.843      0.847      0.702\n",
      "              elephant         53         91      0.993      0.571      0.793      0.626\n",
      "                 rhino         55         85      0.956      0.906      0.944      0.804\n",
      "                 zebra         59        114      0.961      0.675      0.797      0.624\n",
      "Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val61\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.3_v1/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 1764.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.3_v1/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.808      0.664       0.76      0.587\n",
      "               buffalo         62         89      0.676      0.787       0.81      0.659\n",
      "              elephant         53         91      0.804      0.495      0.671      0.502\n",
      "                 rhino         55         85       0.86      0.867      0.893      0.703\n",
      "                 zebra         59        114       0.89      0.509      0.665      0.482\n",
      "Speed: 0.6ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val62\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.3_v2/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 1898.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.3_v2/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.727      0.516      0.615      0.443\n",
      "               buffalo         62         89      0.518      0.685      0.656      0.507\n",
      "              elephant         53         91      0.741      0.363       0.53      0.372\n",
      "                 rhino         55         85      0.729      0.647       0.74      0.551\n",
      "                 zebra         59        114       0.92      0.368      0.534      0.343\n",
      "Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val63\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results_bernoulli = {}\n",
    "# Noisy dataset\n",
    "noises = {\"gaussian\": [0.1, 0.2], \"bernoulli\": [0.1, 0.3]}\n",
    "for noise_type in [\"bernoulli\"]:\n",
    "    results_bernoulli[noise_type] = dict()\n",
    "    for noise in noises[noise_type]:\n",
    "        results_bernoulli[noise_type][noise] = dict()\n",
    "        for model in [\"v0\", \"v1\", \"v2\"]:\n",
    "            inference_data = model_tuned.val(\n",
    "                data=f\"wildlife_{noise_type}_{noise}_{model}.yaml\"\n",
    "            )\n",
    "            # Info to save\n",
    "            info = {\n",
    "                \"precision\": inference_data.box.p,\n",
    "                \"recall\": inference_data.box.r,\n",
    "                \"mAP\": inference_data.box.all_ap,\n",
    "                \"confusion_matrix\": inference_data.confusion_matrix,\n",
    "            }\n",
    "            results_bernoulli[noise_type][noise][model] = info.copy()\n",
    "\n",
    "with open(\"results_detection_bernoulli_yolo.pckl\", \"wb\") as file:\n",
    "    pickle.dump(results_bernoulli, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load clean, Gaussian and Bernoulli results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results_detection_clean_yolo.pckl\", \"rb\") as file:\n",
    "    results_clean = pickle.load(file)\n",
    "with open(\"results_detection_gaussian_yolo.pckl\", \"rb\") as file:\n",
    "    results_gaussian = pickle.load(file)\n",
    "with open(\"results_detection_bernoulli_yolo.pckl\", \"rb\") as file:\n",
    "    results_bernoulli = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.942 0.91  0.827]\n",
      " [0.951 0.899 0.824]\n",
      " [0.909 0.876 0.802]\n",
      " [0.965 0.963 0.873]\n",
      " [0.945 0.903 0.808]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'v2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 52\u001b[0m\n\u001b[1;32m     48\u001b[0m         matrixes\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mhstack(matrix_kind))\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack(matrixes)\n\u001b[0;32m---> 52\u001b[0m res_matrix_gaussian \u001b[38;5;241m=\u001b[39m \u001b[43mget_res_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_gaussian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgaussian\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mv2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m res_matrix_beroulli \u001b[38;5;241m=\u001b[39m get_res_matrix(results_bernoulli, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbernoulli\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.3\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[5], line 27\u001b[0m, in \u001b[0;36mget_res_matrix\u001b[0;34m(result, noise_type, noises, model_kinds)\u001b[0m\n\u001b[1;32m     25\u001b[0m matrix_kind \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kind \u001b[38;5;129;01min\u001b[39;00m model_kinds:\n\u001b[0;32m---> 27\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnoise_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     28\u001b[0m     matr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m     29\u001b[0m         (\u001b[38;5;28mlen\u001b[39m(indexes) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     30\u001b[0m     )  \u001b[38;5;66;03m# matrix that we update with the values to print\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     matr[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     32\u001b[0m         res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(),\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;241m*\u001b[39mres[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     34\u001b[0m     ]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'v2'"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "names = [\"Buffalo\", \"Elephant\", \"Rhino\", \"Zebra\"]\n",
    "indexes = range(4)\n",
    "# Clean dataset\n",
    "matr_cleaned = np.zeros((len(indexes) + 1, 3 * 1))\n",
    "\n",
    "matr_cleaned[:, 0] = [\n",
    "    results_clean[\"clean\"][\"precision\"].mean(),\n",
    "    *results_clean[\"clean\"][\"precision\"],\n",
    "]\n",
    "matr_cleaned[:, 1] = [\n",
    "    results_clean[\"clean\"][\"recall\"].mean(),\n",
    "    *results_clean[\"clean\"][\"recall\"],\n",
    "]\n",
    "# mAP50-95\n",
    "mAP50_c = np.array([results_clean[\"clean\"][\"mAP\"][j].mean() for j in indexes])\n",
    "matr_cleaned[:, 2] = [mAP50_c.mean(), *mAP50_c]\n",
    "print(matr_cleaned)\n",
    "\n",
    "\n",
    "def get_res_matrix(result, noise_type, noises, model_kinds):\n",
    "    matrixes = []\n",
    "    for noise in noises:\n",
    "        # V0\n",
    "        matrix_kind = []\n",
    "        for kind in model_kinds:\n",
    "            res = result[noise_type][noise][kind]\n",
    "            matr = np.zeros(\n",
    "                (len(indexes) + 1, 3 * 1)\n",
    "            )  # matrix that we update with the values to print\n",
    "            matr[:, 0] = [\n",
    "                res[\"precision\"].mean(),\n",
    "                *res[\"precision\"],\n",
    "            ]\n",
    "            matr[:, 1] = [\n",
    "                res[\"recall\"].mean(),\n",
    "                *res[\"recall\"],\n",
    "            ]\n",
    "            # mAP50-95\n",
    "            mAP50 = np.array([res[\"mAP\"][j].mean() for j in indexes])\n",
    "            matr[:, 2] = [\n",
    "                mAP50.mean(),\n",
    "                *mAP50,\n",
    "            ]\n",
    "            matrix_kind.append(matr)\n",
    "\n",
    "        matrixes.append(np.hstack(matrix_kind))\n",
    "    return np.vstack(matrixes)\n",
    "\n",
    "\n",
    "res_matrix_gaussian = get_res_matrix(results_gaussian, \"gaussian\", [0.1, 0.2], [\"v2\"])\n",
    "res_matrix_beroulli = get_res_matrix(results_bernoulli, \"bernoulli\", [0.1, 0.3], [\"v2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All & 255 && 0.942& 0.91& 0.827\\\\ \n",
      "Buffalo & 89 && 0.951& 0.899& 0.824\\\\ \n",
      "Elephant & 91 && 0.909& 0.876& 0.802\\\\ \n",
      "Rhino & 85 && 0.965& 0.963& 0.873\\\\ \n",
      "Zebra & 114 &&0.945& 0.903& 0.808\\\\ \n",
      "\n",
      "All & 255 && 0.911& 0.746& 0.676& 0.9& 0.75& 0.672\\\\ \n",
      "Buffalo & 89 && 0.949& 0.742& 0.735& 0.867& 0.854& 0.752\\\\ \n",
      "Elephant & 91 && 0.818& 0.741& 0.62& 0.874& 0.637& 0.601\\\\ \n",
      "Rhino & 85 && 0.891& 0.882& 0.77& 0.903& 0.918& 0.781\\\\ \n",
      "Zebra & 114 &&0.986& 0.62& 0.581& 0.958& 0.593& 0.554\\\\ \n",
      "All & 255 && 0.87& 0.693& 0.606& 0.804& 0.617& 0.513\\\\ \n",
      "Buffalo & 89 && 0.937& 0.673& 0.667& 0.775& 0.695& 0.601\\\\ \n",
      "Elephant & 91 && 0.8& 0.648& 0.545& 0.763& 0.532& 0.484\\\\ \n",
      "Rhino & 85 && 0.783& 0.847& 0.664& 0.784& 0.853& 0.638\\\\ \n",
      "Zebra & 114 &&0.958& 0.604& 0.548& 0.894& 0.386& 0.329\\\\ \n",
      "\n",
      "All & 255 && 0.902& 0.798& 0.735& 0.933& 0.812& 0.739\\\\ \n",
      "Buffalo & 89 && 0.8& 0.896& 0.758& 0.897& 0.884& 0.774\\\\ \n",
      "Elephant & 91 && 0.934& 0.67& 0.687& 0.907& 0.746& 0.677\\\\ \n",
      "Rhino & 85 && 0.941& 0.906& 0.826& 0.96& 0.918& 0.838\\\\ \n",
      "Zebra & 114 &&0.933& 0.719& 0.67& 0.969& 0.702& 0.669\\\\ \n",
      "All & 255 && 0.906& 0.764& 0.709& 0.827& 0.655& 0.589\\\\ \n",
      "Buffalo & 89 && 0.802& 0.888& 0.747& 0.67& 0.742& 0.655\\\\ \n",
      "Elephant & 91 && 0.945& 0.569& 0.644& 0.852& 0.505& 0.528\\\\ \n",
      "Rhino & 85 && 0.946& 0.906& 0.809& 0.889& 0.847& 0.696\\\\ \n",
      "Zebra & 114 &&0.929& 0.693& 0.635& 0.897& 0.526& 0.477\\\\ \n"
     ]
    }
   ],
   "source": [
    "# Latex table formatting\n",
    "def latex_table_formatting(res_matrix):\n",
    "    rows = [\n",
    "        \"All & 255 && \",\n",
    "        \"Buffalo & 89 && \",\n",
    "        \"Elephant & 91 && \",\n",
    "        \"Rhino & 85 && \",\n",
    "        \"Zebra & 114 &&\",\n",
    "    ]\n",
    "    if len(res_matrix) > 5:\n",
    "        rows += [\n",
    "            \"All & 255 && \",\n",
    "            \"Buffalo & 89 && \",\n",
    "            \"Elephant & 91 && \",\n",
    "            \"Rhino & 85 && \",\n",
    "            \"Zebra & 114 &&\",\n",
    "        ]\n",
    "    for i in range(len(rows)):\n",
    "        print(\n",
    "            rows[i] + \"& \".join([str(round(r, 3)) for r in res_matrix[i]]),\n",
    "            end=\"\\\\\\\\ \\n\",\n",
    "        )\n",
    "\n",
    "\n",
    "latex_table_formatting(matr_cleaned)\n",
    "print(\"\")\n",
    "latex_table_formatting(res_matrix_gaussian)\n",
    "print(\"\")\n",
    "latex_table_formatting(res_matrix_beroulli)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
