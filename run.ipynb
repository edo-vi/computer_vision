{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "path_to_base_yolo = \"/home/edoardo/aiproject/runs/detect/300/weights/best.pt\"\n",
    "model_tuned = YOLO(path_to_base_yolo)\n",
    "\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for Gaussian noise (V0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n",
      "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife/valid/labels.cache... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   7%|â–‹         | 1/15 [00:00<00:01,  7.31it/s]/home/edoardo/anaconda3/envs/aiproject/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.942       0.91      0.953      0.827\n",
      "               buffalo         62         89      0.951      0.899      0.948      0.824\n",
      "              elephant         53         91      0.909      0.876      0.931      0.802\n",
      "                 rhino         55         85      0.965      0.963      0.975      0.873\n",
      "                 zebra         59        114      0.945      0.903      0.959      0.808\n",
      "Speed: 0.5ms preprocess, 2.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_gaussian_0.1_v0/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 3249.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_gaussian_0.1_v0/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.911      0.746      0.842      0.676\n",
      "               buffalo         62         89      0.949      0.742      0.876      0.735\n",
      "              elephant         53         91      0.818      0.741      0.775       0.62\n",
      "                 rhino         55         85      0.891      0.882      0.931       0.77\n",
      "                 zebra         59        114      0.986       0.62      0.785      0.581\n",
      "Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_gaussian_0.1_v1/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 1473.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_gaussian_0.1_v1/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379        0.9       0.75      0.835      0.672\n",
      "               buffalo         62         89      0.867      0.854      0.893      0.752\n",
      "              elephant         53         91      0.874      0.637      0.752      0.601\n",
      "                 rhino         55         85      0.903      0.918      0.939      0.781\n",
      "                 zebra         59        114      0.958      0.593      0.756      0.554\n",
      "Speed: 0.6ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_gaussian_0.2_v0/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 2429.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_gaussian_0.2_v0/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379       0.87      0.693      0.786      0.606\n",
      "               buffalo         62         89      0.937      0.673      0.798      0.667\n",
      "              elephant         53         91        0.8      0.648       0.71      0.545\n",
      "                 rhino         55         85      0.783      0.847      0.868      0.664\n",
      "                 zebra         59        114      0.958      0.604      0.768      0.548\n",
      "Speed: 0.6ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_gaussian_0.2_v1/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 2611.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_gaussian_0.2_v1/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.804      0.617      0.705      0.513\n",
      "               buffalo         62         89      0.775      0.695       0.77      0.601\n",
      "              elephant         53         91      0.763      0.532      0.642      0.484\n",
      "                 rhino         55         85      0.784      0.853       0.86      0.638\n",
      "                 zebra         59        114      0.894      0.386      0.548      0.329\n",
      "Speed: 0.6ms preprocess, 1.6ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val5\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v0/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 3469.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v0/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        225        379      0.902      0.798      0.884      0.735\n",
      "               buffalo         62         89        0.8      0.896      0.922      0.758\n",
      "              elephant         53         91      0.934       0.67       0.83      0.687\n",
      "                 rhino         55         85      0.941      0.906      0.959      0.826\n",
      "                 zebra         59        114      0.933      0.719      0.824       0.67\n",
      "Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val6\u001b[0m\n",
      "Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.0 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 7951MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v1/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 3132.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/edoardo/aiproject/datasets/wildlife_bernoulli_0.1_v1/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "# Clean dataset\n",
    "results[\"clean\"] = model_tuned.val(data=\"wildlife.yaml\")\n",
    "\n",
    "# Noisy dataset\n",
    "noises = {\"gaussian\": [0.1, 0.2], \"bernoulli\": [0.1, 0.3]}\n",
    "for noise_type in [\"gaussian\", \"bernoulli\"]:\n",
    "    results[noise_type] = dict()\n",
    "    for noise in noises[noise_type]:\n",
    "        results[noise_type][noise] = dict()\n",
    "        for model in [\"v0\", \"v1\"]:\n",
    "            results[noise_type][noise][model] = model_tuned.val(\n",
    "                data=f\"wildlife_{noise_type}_{noise}_{model}.yaml\"\n",
    "            )\n",
    "\n",
    "with open(\"results_detection_yolo.pckl\", \"wb\") as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.944 0.754 0.724 0.843 0.854 0.752]\n",
      " [0.798 0.758 0.63  0.885 0.648 0.606]\n",
      " [0.873 0.894 0.762 0.905 0.892 0.776]\n",
      " [0.973 0.63  0.582 0.944 0.594 0.546]\n",
      " [0.897 0.759 0.675 0.894 0.747 0.67 ]]\n",
      "[[0.889 0.629 0.661 0.824 0.674 0.603]\n",
      " [0.759 0.623 0.533 0.84  0.56  0.482]\n",
      " [0.77  0.835 0.656 0.777 0.788 0.624]\n",
      " [0.972 0.623 0.56  0.905 0.351 0.325]\n",
      " [0.848 0.678 0.602 0.837 0.593 0.508]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "names = results_gaussian_v0[0].names\n",
    "indexes = results_gaussian_v0[0].ap_class_index  # class indexes\n",
    "# Clean dataset\n",
    "matr_cleaned = np.zeros((len(indexes) + 1, 3 * 1))\n",
    "\n",
    "matr_cleaned[:, 0] = [*results_cleaned.box.p, results_cleaned.box.p.mean()]\n",
    "matr_cleaned[:, 1] = [*results_cleaned.box.r, results_cleaned.box.r.mean()]\n",
    "# mAP50-95\n",
    "mAP50_c = np.array([results_cleaned.box.all_ap[j].mean() for j in indexes])\n",
    "matr_cleaned[:, 2] = [*mAP50_c, mAP50_c.mean()]\n",
    "for i, res in enumerate(results_gaussian_v0):\n",
    "    matr = np.zeros(\n",
    "        (len(indexes) + 1, 3 * 1)\n",
    "    )  # matrix that we update with the values to print\n",
    "    matr[:, 0] = [*res.box.p, res.box.p.mean()]\n",
    "    matr[:, 1] = [*res.box.r, res.box.r.mean()]\n",
    "    # mAP50-95\n",
    "    mAP50 = np.array([res.box.all_ap[j].mean() for j in indexes])\n",
    "    matr[:, 2] = [*mAP50, mAP50.mean()]\n",
    "\n",
    "    # For\n",
    "    res1 = results_gaussian_v1[i]\n",
    "    matr1 = np.zeros(\n",
    "        (len(indexes) + 1, 3 * 1)\n",
    "    )  # matrix that we update with the values to print\n",
    "    matr1[:, 0] = [*res1.box.p, res1.box.p.mean()]\n",
    "    matr1[:, 1] = [*res1.box.r, res1.box.r.mean()]\n",
    "    # mAP50-95\n",
    "    mAP50_1 = np.array([res1.box.all_ap[j].mean() for j in indexes])\n",
    "    matr1[:, 2] = [*mAP50_1, mAP50_1.mean()]\n",
    "    print(np.hstack([matr, matr1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for Gaussian noise (V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
